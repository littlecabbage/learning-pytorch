{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unlike-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.10 多层感知机的简洁实现\n",
    "# start at 01-26 on mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "indirect-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import d2lzh_pytorch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-buffalo",
   "metadata": {},
   "source": [
    "# 1. 定义模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-meeting",
   "metadata": {},
   "source": [
    "## 1.1 定义一个FlattenLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "complete-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因为前面我们数据返回的每个batch样本x的形状为(batch_size, 1, 28, 28),\n",
    "# 所以我们要先用view()将x的形状转换成(batch_size, 784)才送入全连接层。\n",
    "class FlattenLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FlattenLayer, self).__init__()\n",
    "    def forward(self, x): \n",
    "        return x.view(x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-kruger",
   "metadata": {},
   "source": [
    "## 1.2 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "important-madness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 隐藏层单元设置为256\n",
    "num_inputs, num_outputs, num_hidden = 784, 10, 256\n",
    "\n",
    "\n",
    "net = nn.Sequential(\n",
    "    FlattenLayer(),\n",
    "    nn.Linear(num_inputs, num_hidden), \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(num_hidden, num_outputs)\n",
    ")\n",
    "\n",
    "\n",
    "for params in net.parameters():\n",
    "    init.normal_(params, mean = 0, std = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-three",
   "metadata": {},
   "source": [
    "# 2. 读取数据并训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-arlington",
   "metadata": {},
   "source": [
    "## 2.1 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "engaged-storm",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-recipient",
   "metadata": {},
   "source": [
    "## 2.2 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adjusted-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-childhood",
   "metadata": {},
   "source": [
    "## 2.3 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "charming-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-action",
   "metadata": {},
   "source": [
    "# 2.4 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "revolutionary-cancellation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.0015, train acc 0.854, test acc 0.845\n",
      "epoch 2, loss 0.0014, train acc 0.866, test acc 0.810\n",
      "epoch 3, loss 0.0014, train acc 0.870, test acc 0.843\n",
      "epoch 4, loss 0.0013, train acc 0.876, test acc 0.866\n",
      "epoch 5, loss 0.0013, train acc 0.880, test acc 0.844\n"
     ]
    }
   ],
   "source": [
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for X,y in data_iter:\n",
    "        acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
    "        n += y.shape[0]\n",
    "        \n",
    "    return acc_sum / n\n",
    "\n",
    "num_epochs = 5 \n",
    "\n",
    "def train(net, train_iter, test_iter, loss, num_eophs, batch_size, params=None, lr=None, optimizer=None):\n",
    "    for epoch in range(num_epoch):\n",
    "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
    "        # train_l_sum, train_acc_sum, n= train_one_epoch(train_iter)\n",
    "        for X,y in train_iter:\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y).sum()\n",
    "            \n",
    "            \n",
    "            if optimizer is not None:\n",
    "                optimizer.zero_grad()\n",
    "            elif params is not None and params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "                    \n",
    "            \n",
    "            l.backward()\n",
    "            \n",
    "            if optimizer is None:\n",
    "                d2l.sgd(params, lr, batch_size)\n",
    "            else:\n",
    "                optimizer.step()\n",
    "                \n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f' % (epoch + 1, train_l_sum/n, train_acc_sum/n, test_acc))\n",
    "        \n",
    "        \n",
    "train(net, train_iter, test_iter, loss, num_epochs, batch_size, None, None, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-plate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finished at 0:26"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Voygern",
   "language": "python",
   "name": "voygern"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
